% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sandbox.R
\name{datashield.login}
\alias{datashield.login}
\title{Extends datashield.login from package opal}
\usage{
datashield.login(which_connections = names(local_conns), ...)
}
\arguments{
\item{which_connections}{optional, a vector containing the names of the local "sessions" to "connect" to. Normally the output
of dssCreateFakeServers (or a subset of it)}

\item{...}{optional, the parameters for opal::datashield.login (logins dataframe, etc) in case we want to connect to any remote, real opal servers}
}
\value{
a vector containing the names of all the establised connections (real and fake)
}
\description{
Creates the necessary software infrastructure for the usual opal and datashield functions to be able to run in
local pseudo-sessions as well as in remote real sessions
}
\details{
This function creates the final connection object and assigns it in the global environment. Moreover:
* If necessary establishes connections to remote, real servers
* Creates variants of the generics datashield.assign , datashield.aggregate and datashield.symbols that work on the local pseudo sessions.
* Returns a vector that can be used in various dsBaseClient (and other) functions. Attention: these functions will work only if
called with an explicit datasources parameter (ex: ds.var('some_vector', **datasources = myopals**) and not: ds.var('some_vector'))
}
\examples{
# Mixed opal connections, local(fake, in my session) + remote(real)
# Read a real connection dataframe from a file
logindata <- read.delim('/path to your/logindata.txt')
# say it looks like this:
logindata
  server                     url       user      password    table
1  real1  https://remote.opal.node  some_user   some_pass   proj.TABLE
# create 2 local connections:
x <- dssCreateFakeServers('all_conns',c('fake1', 'fake2'))
#login:
opals <- datashield.login(x,logindata)
# opals contains 3 connections, 2 locals, one remote. You can examine them:
opals
all_conns
# create a function called partial_data in the local session as well as on the remote node
# on the remote node this function must be published as an aggregate method:
partial_data <- function (what, start = NULL, end = NULL) {
 data(list = list(what), envir = environment())
 my.df <- get(what)
 if (is.null(start)) {
   start <- 1
 }
 if (is.null(end)) {
   end <- nrow(my.df)
 }
 my.df <- my.df[start:end, ]
 assign(what, my.df, pos = parent.frame())
 TRUE
}
the above loads a piece of an R dataset
# we can use it to load 3 chunks of the 'iris' dataset, each on a different node
datashield.aggregate(opals['fake1'], as.symbol('partial.data("iris", 1, 40)'))
datashield.aggregate(opals['fake2'], as.symbol('partial.data("iris", 41, 100)'))
datashield.aggregate(opals['real1'], as.symbol('partial.data("iris", 101, 150)'))
# run some ds... commands:
ds.summary('iris', datasources = opals)
ds.mean('iris', datasources = opals) # always specify the datasources explicitly
# where's my local data?
ls(envir = all_conns$locals$fake1$envir)
ls(envir = all_conns$locals$fake2$envir)

datashield.logout(opals)
}
\seealso{
\link{dssCreateFakeServers}
}
